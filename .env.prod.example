# Production Environment Configuration
# Copy this file to .env.prod and update with your settings

# Server Configuration
NODE_ENV=production
PORT=3001

# Redis Configuration (External)
# Use host.docker.internal to connect to host machine's Redis
REDIS_URL=redis://host.docker.internal:6379

# LLM API URL (vLLM chat completions endpoint)
LLM_API_URL=https://your-production-llm-server:8000/v1/chat/completions

# LLM Model path
# Example: /data/models/gpt-oss-120b
LLM_MODEL=/path/to/your/model

# SSL Configuration
# WARNING: Set to 1 or remove this line for production!
# Only use 0 if your LLM server has self-signed certificates
# NODE_TLS_REJECT_UNAUTHORIZED=0

# CORS Configuration
# Specify your production frontend URLs
ALLOWED_ORIGINS=https://your-frontend-domain.com
